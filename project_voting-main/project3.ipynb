{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20673812-4dc7-4b66-9dc8-b4b9be6876cf",
   "metadata": {},
   "source": [
    "# Project #3\n",
    "## Foundations of Machine Learning\n",
    "\n",
    "The purpose of this project is to build models to predict the outcome of the 2024 presidential election in Virginia and provide quantitative information about the precision of the prediction.\n",
    "  \n",
    "The data include:\n",
    "  \n",
    "  - `voting_VA.csv`: Voting data for presidential elections for Virginia from 2000 to 2020\n",
    "  - `nhgis_county_data`: A folder containing many county-level summary stats for every county in the U.S. This is the most complete county-level data I could find. If you go to the IPUMS NHGIS web site, you can see what else is available (there are hundreds of variables, and I chose a large number of obvious ones; perhaps some useful ones escaped my attention). For standard IPUMS microdata, the county is not available for privacy reasons.\n",
    "  - `county_adjacencies.csv`: I looked up the neighbors, districts, FIPS county identifiers, and populations in 2022 for all counties and cities in Virginia.\n",
    "  - At [https://vgin.vdem.virginia.gov/datasets/777890ecdb634d18a02eec604db522c6/about] there is a shapefile for making choropleth plots called \"Shapefile Download (Clipped to VIMS shoreline)\"\n",
    "  -  I put together a starter notebook called `va_voting.ipynb` that shows how to combine these files and make nice maps\n",
    " \n",
    "You can use whatever additional data you want to create a predictive algorithm for outcomes, based on the `voting_VA.csv` and `nhgis_county_data` data or other sources you think would be useful. You can focus on Virginia data, but in principle, you could use data from the entire country. Since you only have five observations for each county on its own in Virginia, you can, in principle, use the additional data about county composition or data from other states to build richer and more powerful predictive models than just the sample average for each county (e.g 3 observations of `D` winning and 2 of `R` winning implies a probability 3/5 of `D` winning). You could also gather and use data about past candidates to see if there are county-candidate interaction effects that improve your model's performance. Indeed, 2024 might be a Biden-Trump rematch, in which case past data might be extremely relevant.\n",
    "    \n",
    "## Paper format\n",
    "\n",
    "The format of the paper should be:\n",
    "\n",
    "- Summary: A one paragraph description of the question, methods, and results (about 350 words).\n",
    "- Data: One to two pages discussing the data and key variables, and any challenges in reading, cleaning, and preparing them for analysis.\n",
    "- Results: Two to five pages providing visualizations, statistics, tables, a discussion of your methodology, and a presentation of your main results. In particular, how are you approaching the prediction problem? How confident are you about your assessments that counties will support one party or the other?\n",
    "- Conclusion: One to two pages summarizing the project, defending it from criticism, and suggesting additional work that was outside the scope of the project.\n",
    "- Appendix: If you have a significant number of additional plots or table that you feel are essential to the project, you can put any amount of extra content at the end and reference it from the body of the paper.\n",
    "\n",
    "Submit your work in your group's GitHub repo.\n",
    "\n",
    "## Group Work and Submission\n",
    "\n",
    "Each group will submit their work in a GitHub repo. The repo can be managed by a group member or arranged by github.com/DS3001.\n",
    "\n",
    "Half of each student's grade is based on their commits to the repo. Each student is expected to do something\n",
    "specific that contributes to the overall project outcome. Since commits are recorded explicitly by Git/GitHub,\n",
    "this is observable. A student can contribute by cleaning data, creating visualizations, or writing about results,\n",
    "but everyone has to do something substantial. A student's work doesn't need to make it into the final report\n",
    "to be valuable and substantial, and fulfill the requirement to make a contribution to the project.\n",
    "\n",
    "The other half of each student's grade is based on the report. Groups will work together on combining\n",
    "results and writing up findings in a Jupyter notebook, using code chunks to execute Python commands and\n",
    "markdown chunks to structure the paper and provide exposition. The notebook should run on Colab or\n",
    "Rivana from beginning to end without any errors.\n",
    "\n",
    "## Criteria\n",
    "\n",
    "The project is graded based on four criteria:\n",
    "\n",
    "- Project Concept: What is the strategy for building and testing the group's predictive models? How are the models embedded in the decision problem of gerrymandering Virginia?  \n",
    "- Wrangling, EDA, and Visualization: How are are missing values handled? For variables with large numbers of missing values, to what extent do the data and documentation provide an explanation for the missing data? If multiple data sources are used, how are the data merged? For the main variables in the analysis, are the relevant data summarized and visualized through a histogram or kernel density plot where appropriate? Are basic quantitative features of the data addressed and explained? How are outliers characterized and addressed? \n",
    "- Analysis: What are the groups' main findings? Do the tables, plots, and statistics support the conclusions? If the gerrymandering strategy succeeds, what are the results and how extreme can the map be drawn for each side? If the gerrymandering strategy fails, is there a thoughtful discussion about the challenges and limitations?\n",
    "- Replication/Documentation: Is the code appropriately commented? Can the main results be replicated from the code and original data files? Are significant choices noted and explained?\n",
    "\n",
    "Each of the four criteria are equally weighted (25 points out of 100).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
