{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdaeb5b9-a78d-4439-8372-341b3e8cc2ea",
   "metadata": {},
   "source": [
    "# Assignment #5: Probability and Bootstrapping\n",
    "## Foundations of Machine Learning\n",
    "## ` ! git clone https://www.github.com/DS3001/the_bootstrap`\n",
    "## Do two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5d151-f097-44d8-9952-740865be4e2b",
   "metadata": {},
   "source": [
    "**Q1.** A die is fair if every face is equally likely. A die has six sides if it has six faces labelled 1, 2, ... , 6.\n",
    "\n",
    "1. Imagine rolling two dice, $d_1$ and $d_2$. Let $R_{min}$ be the lesser value of the two face values. What is the probability of getting a 1, 2, 3, 4, 5, or 6? Which values are more or less likely compared to the roll of a single six-sided die? What is the expected value of $R_{min}$? Plot the probability and cumulative distribution functions for $R_{min}$. Compute this by hand and simulate it using the law of large numbers.\n",
    "2. Imagine rolling three dice, $d_1$, $d_2$, and $d_3$. Let $R_{med}$ be the middle of the three face values. So if you roll 2, 3 and 4, the middle value is 3, and if you roll 2, 4, 4, the middle value is 4, and so on. What is the probability of getting a 1, 2, 3, 4, 5, or 6? Which values are more or less likely compared to the roll of a single six-sided die? What is the expected value of $R_{med}$? Plot the probability and cumulative distribution functions for $R_{med}$. I recommend using simulations and the law of large numbers.\n",
    "3. Imagine rolling a die. If you roll 1, 2, 3, 4, or 5, add that number to your total and stop; if you roll a six, add that number to your total and roll the die again. So you could roll, say, two sixes and then a four, and get a total of 16, or one three and get a total of 3, or twelve sixes and 1 and get 72, and so on. Write code to simulate this process, and determine its expected value using the law of large numbers. What is the probability of getting a total of 1, 2, 3, ... and so on, in your simulation? I recommend using simulations and the law of large numbers.  (Hint: The `while` loop might be useful in this case.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b5fc6-4aea-40f5-b9c4-a9563a138f62",
   "metadata": {},
   "source": [
    "**Q2.** This question refers to the `mammogram.csv` data. It has two variables, `treatment` which takes the values `control` or `mammogram`, and `breast_cancer_death`, which takes the values `no` or `yes`. This is an experiment that followed 89,835 women for 25 years to see if mammograms were superior to more traditional breast cancer screenings in preventing breast cancer deaths.\n",
    "\n",
    "1. Cross tabulate `treatment` and `breast_cancer_death`. What is the difference in 25-year survival rates between the control and mammogram groups?\n",
    "2. Bootstrap the densities and distributions of survival rates for the two groups. \n",
    "3. Construct a 99% confidence interval for the difference in outcomes bewteen the two groups. Does it include zero?\n",
    "4. We're not doctors, these were just some intriguing data, and the information about the patients is extremely sparse. Why might these data over/understate the conclusions you've reached? What other data would you like to have to better understand or criticize your results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f07ca-300a-4e1c-9c3c-9ed39a97badc",
   "metadata": {},
   "source": [
    "**Q3.** This question refers to the `diabetes_hw.csv` data. It contains two variables, `outcome` and `treatment`. Each is looking at whether an individual's diabetes was successfully treated (`outcome==success`) with `lifestyle` interventions like exercises and diets, a drug denoted by `met` (metformin), or a drug denoted by `rosi` (rosiglitazone), or not (`outcome==failure`). Treatment success means that the individual no longer needs to be treated with insulin, while failure means the patient still required insulin injections after treatment.\n",
    "\n",
    "1. Cross tabulate `treatment` and `outcome`.\n",
    "2. Compute the the proportion of successes for each treatment. Which treatment appears to be the most effective?\n",
    "3. Bootstrap the density and distribution of the proportion of successes for each interventions. Create empirical CDF and kernel density plots that are grouped  by treatment type. Which treatment appears to be the most effective?\n",
    "4. For each comparison (lifestyle versus met, met versus rosi, rosi versus lifestyle), bootstrap the distribution of the difference in outcomes. At the 90% level of confidence, which pairwise treatment comparisons are significantally different?\n",
    "5. Which treatment appears to be the most effective overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec729f2a-0178-4c11-a55d-d236c1252f29",
   "metadata": {},
   "source": [
    "**Q4.** The goal of the question is to incorporate features/covariates/predictors/explanatory variables into the kind of treatment effect comparisons done in the previous questions. This question refers to the `heart_hw.csv` data. It contains three variables:\n",
    "\n",
    "  - `y`: Whether the individual survived, coded 0 for death and 1 for survival\n",
    "  - `age`: Patient's age\n",
    "  - `transplant`: `control` for not receiving a transplant and `treatment` for receiving a transplant\n",
    "\n",
    "1. Compute (a) the proportion of people who survive in the control group who do not receive a transplant, and (b) the difference between the proportion of people who survive in the treatment group and the proportion of people who survive in the control group (the average treatment effect).\n",
    "2. Regress `y` on `transplant` using a linear model. How does the constant/intercept of the regression and the coefficient on transplant compare to your answers from part 1? Explain carefully.\n",
    "3. We'd like to include `age` in the regression, since it's reasonable to expect that older patients are less likely to survive an extensive surgery like a heart transplant. Regress `y` on transplant, age, and transplant$\\times$age. You can do this using a linear regression. How do the intercept and the coefficient on `transplanttreatment` change?\n",
    "4. Add the intercept and the transplanttreatment coefficients together from part 3. What do you get? Does that make sense? What are you missing in predicting survival probability this way?\n",
    "5. Plot the predicted survival probability by age for people who receive a heart transplant and those who don't. Describe what you see.\n",
    "6. Imagine someone suggests using these kinds of models to select who receives organ transplants; perhaps the CDC or NIH starts using a scoring algorithm to decide who is contacted about a potential organ transplant. What are your concerns about how it is built and how it is deployed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33cb8d-f64e-4cf9-8b1b-193f280ee66c",
   "metadata": {},
   "source": [
    "**Q5.** This question refers to `mn_police_use_of_force.csv`. This includes reports on the Minnesota police department's use of force from 1/1/2016 to 8/31/2021. This is, perhaps, a potentially controversial set of data to look at, but I imagine many students sincerely want to think about the difficult questions that society grapples with, what kind of evidence exists, and how they might analyze it using tools from class. We should also always be skeptical of data, particularly when the source has an interest in controlling our beliefs and can define or omit data to advance its interests.\n",
    "\n",
    "The data include:\n",
    "- `response_datetime`: DateTime of police response.\n",
    "- `problem`: Problem that required police response.\n",
    "- `is_911_call`: Whether response was iniated by call to 911.\n",
    "- `primary_offense`: Offense of subject.\n",
    "- `subject_injury`: Whether subject was injured Yes/No/null.\n",
    "- `force_type`: Type of police force used.\n",
    "- `force_type_action`: Detail of police force used.\n",
    "- `race`: Race of subject.\n",
    "- `sex`: Gender of subject.\n",
    "- `age`: Age of subject.\n",
    "- `type_resistance`: Resistance to police by subject.\n",
    "- `precinct`: Precinct where response occurred.\n",
    "- `neighborhood`: Neighborhood where response occurred.\n",
    "\n",
    "To answer the following questions, you need to make choices about what to focus on and how to conduct the analysis. Explain your choices and defend them where appropriate.\n",
    "\n",
    "1. Are there significant missing values? In what variables? In particular, consider `subject_injury`. Clearly discuss what you find.\n",
    "2. Cross tabulate `race` and `force_type`. What patterns do you notice? Use the options `normalize='columns'` and `normalize='rows'`, and `margins=True` to explore different ways of normalizing the data to better understand results by race.\n",
    "3. Use tables, crosstabulation and the bootstrap to investigate the extent to which `force_type` varies between different races.\n",
    "4. Use tables, crosstabulation and the bootstrap to investigate the extent to which `Maximal Restraint Technique` varies between different races.\n",
    "5. Use tables, crosstabulation and the bootstrap to investigate the extent to which `subject_injury` varies between different races. Please be clear about how you address the large number of NaN's (you might even use the other data to look at what predicts a NaN in this column to see if there are systematic patterns).\n",
    "6. Summarize your findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
